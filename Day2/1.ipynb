{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682b5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8042a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.,  4.,  4.],\n",
      "        [ 6.,  6.,  6.],\n",
      "        [ 8.,  8.,  8.],\n",
      "        [10., 12., 14.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2.0, 2.0, 2.0], [3.0,3.0,3.0], [4.0,4.0,4.0],[5.0, 6.0, 7.0]], requires_grad=True)# giá trị đưa vào phải là float\n",
    "# requires_grad=True cho phép tính đạo hàm\n",
    "y = x ** 2 \n",
    "y = y.backward(torch.ones_like(x)) # truyền vào một tensor cùng kích thước với x để tính đạo hàm \n",
    "# y là một scalar nên phải truyền vào một tensor cùng kích thước với x\n",
    "# nếu y là một tensor có kích thước khác thì sẽ báo lỗi\n",
    "# với x là một số x = torch.tensor(2.0, requires_grad = True) , y.backward() sẽ không cần truyền vào một tensor cùng kích thước với x\n",
    "# y.backward() sẽ tính đạo hàm của y theo x và lưu vào x.grad\n",
    "print(x.grad)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23d83f",
   "metadata": {},
   "source": [
    "Khi đặt requires_grad=True, PyTorch bắt đầu theo dõi toàn bộ phép toán của tensor đó.\n",
    "Mỗi phép toán sẽ được ghi lại trong một đồ thị ngược (backward graph).\n",
    "Khi gọi y.backward(), PyTorch sẽ lan truyền ngược (backpropagation) và tính đạo hàm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc61f90",
   "metadata": {},
   "source": [
    ".backward() mặc định tính đạo hàm của một giá trị đầu ra duy nhất (thường là loss trong mạng nơ-ron), và truyền gradient ngược qua từng phép toán đã thực hiện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a126188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# z = w*x + b\n",
    "z = w * x + b\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)  # None (vì x không dùng làm hàm loss chính)\n",
    "print(w.grad)  # x = 1\n",
    "print(b.grad)  # 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
